{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Init ray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "ray.init(address=\"auto\", ignore_reinit_error=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load default config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load defaulft config\n",
    "import yaml\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "config_path = './configs/Active_v0.yml'\n",
    "\n",
    "with open(config_path) as file:\n",
    "    # The FullLoader parameter handles the conversion from YAML\n",
    "    # scalar values to Python the dictionary format\n",
    "    config = yaml.load(file, Loader=yaml.FullLoader)\n",
    "\n",
    "# create base dir and gr\n",
    "if os.path.exists(config[\"PROJECT\"][\"project_dir\"]) is False:\n",
    "    os.mkdir(config[\"PROJECT\"][\"project_dir\"])\n",
    "\n",
    "if os.path.exists(config[\"PROJECT\"][\"group_dir\"]) is False:\n",
    "    os.mkdir(config[\"PROJECT\"][\"group_dir\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the data to annotate\n",
    "\n",
    "For DataNet we should pass the list of the annotated images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/reminiz/ReminizML2/python_env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/reminiz/ReminizML2/python_env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/reminiz/ReminizML2/python_env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/reminiz/ReminizML2/python_env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/reminiz/ReminizML2/python_env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/reminiz/ReminizML2/python_env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CIFAR10 Training data shape: (50000, 32, 32, 3)\n",
      "CIFAR10 Training label shape (50000, 1)\n",
      "CIFAR10 Test data shape (10000, 32, 32, 3)\n",
      "CIFAR10 Test label shape (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "# Get the data to annotate\n",
    "\n",
    "#############################################################################################\n",
    "# LOAD DATA\n",
    "#############################################################################################\n",
    "from data_utils import CIFAR10Data\n",
    "# Load data\n",
    "cifar10_data = CIFAR10Data()\n",
    "num_classes = len(cifar10_data.classes)\n",
    "x_train, y_train, x_test, y_test = cifar10_data.get_data(subtract_mean=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = list(range(len(x_train)))\n",
    "random.shuffle(indices)\n",
    "labeled_set = indices[:config[\"RUNS\"][\"ADDENDUM\"] ]\n",
    "unlabeled_set = indices[config[\"RUNS\"][\"ADDENDUM\"] :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test with all the images\n",
    "NUM_IMAGES_TEST = len(x_test)\n",
    "# Initialize a labeled dataset by randomly sampling K=ADDENDUM=1,000 data points from the entire dataset.\n",
    "test_set = list(range(NUM_IMAGES_TEST))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "config[\"NETWORK\"][\"INPUT_SIZE\"] =  x_train[0].shape[0]\n",
    "config[\"NETWORK\"][\"CLASSES\"] = cifar10_data.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ACTIVE_ALGO': {'LOSSLEARNING': 1.0},\n",
       " 'DATASET': {'height_shift_range': 4,\n",
       "  'horizontal_flip': True,\n",
       "  'width_shift_range': 4},\n",
       " 'NETWORK': {'CLASSES': ['plane',\n",
       "   'car',\n",
       "   'bird',\n",
       "   'cat',\n",
       "   'deer',\n",
       "   'dog',\n",
       "   'frog',\n",
       "   'horse',\n",
       "   'ship',\n",
       "   'truck'],\n",
       "  'INPUT_SIZE': 32,\n",
       "  'MARGIN': 1.0,\n",
       "  'embedding_size': 128},\n",
       " 'PROJECT': {'Backbone': 'resnet18',\n",
       "  'dataset_name': 'CIFAR',\n",
       "  'group': 'Active_Learning_v1',\n",
       "  'group_dir': '/mnt/Ressources/Andres/Temp_active/runs/Active_Learning_v1',\n",
       "  'project': 'Active_Learning_CIFAR',\n",
       "  'project_dir': '/mnt/Ressources/Andres/Temp_active/runs',\n",
       "  'source': 'CIFAR'},\n",
       " 'RUNS': {'ADDENDUM': 1000,\n",
       "  'CYCLES': 10,\n",
       "  'SUBSET': -1,\n",
       "  'TRIALS': 1,\n",
       "  'test_each': 5},\n",
       " 'TEST': {'batch_size': 128},\n",
       " 'TRAIN': {'Data_augementation': True,\n",
       "  'EPOCH_SLIT': 80,\n",
       "  'EPOCH_WARMUP': 2,\n",
       "  'EPOCH_WHOLE': 120,\n",
       "  'MILESTONES': [160],\n",
       "  'batch_size': 128,\n",
       "  'gamma': 0.1,\n",
       "  'lr': 0.001,\n",
       "  'start_epoch': 0,\n",
       "  'transfer_weight_path': False,\n",
       "  'w_c_loss': 1.0,\n",
       "  'w_l_loss': 1.0,\n",
       "  'wdecay': 0.9995}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "stages = [int(i.split('_')[-1]) for i in os.listdir(config['PROJECT']['group_dir']) if os.path.isdir(os.path.join(config['PROJECT']['group_dir'],i)) and i.startswith('Stage')]\n",
    "stages.sort()\n",
    "stages = {i:[] for i in stages}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "for stage in stages.keys():\n",
    "    path = os.path.join(config['PROJECT']['group_dir'],\"Stage_\"+str(stage),'checkpoint')\n",
    "    path_check_point_file = os.path.join(path,'checkpoint')\n",
    "    temp  =pd.read_csv(path_check_point_file,sep=\"\\\"\",header=None,names=['1','paths','n'])\n",
    "    epochs_checked = [int(i.split('-')[-1]) for i in set(temp.paths.values)]\n",
    "    epochs_checked.sort()\n",
    "    stages[stage] = epochs_checked\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 5\n",
      "0 10\n",
      "0 15\n",
      "0 20\n",
      "0 25\n",
      "0 30\n",
      "0 35\n",
      "0 40\n",
      "0 45\n",
      "0 50\n",
      "0 55\n",
      "0 60\n",
      "0 65\n",
      "0 70\n",
      "0 75\n",
      "0 80\n",
      "0 85\n",
      "0 90\n",
      "0 95\n",
      "0 100\n",
      "0 105\n",
      "0 110\n",
      "0 115\n",
      "0 120\n",
      "0 125\n",
      "0 130\n",
      "0 135\n",
      "0 140\n",
      "0 145\n",
      "0 150\n",
      "0 155\n",
      "0 160\n",
      "0 165\n",
      "0 170\n",
      "0 175\n",
      "0 180\n",
      "0 185\n",
      "0 190\n",
      "0 195\n",
      "0 200\n",
      "1 5\n",
      "1 10\n",
      "1 15\n",
      "1 20\n",
      "1 25\n",
      "1 30\n",
      "1 35\n",
      "1 40\n",
      "1 45\n",
      "1 50\n",
      "1 55\n",
      "1 60\n",
      "1 65\n",
      "1 70\n",
      "1 75\n",
      "1 80\n",
      "1 85\n",
      "1 90\n",
      "1 95\n",
      "1 100\n",
      "1 105\n",
      "1 110\n",
      "1 115\n",
      "1 120\n",
      "1 125\n",
      "1 130\n",
      "1 135\n",
      "1 140\n",
      "1 145\n",
      "1 150\n",
      "1 155\n",
      "1 160\n",
      "1 165\n",
      "1 170\n",
      "1 175\n",
      "1 180\n",
      "1 185\n",
      "1 190\n",
      "1 195\n",
      "1 200\n",
      "2 5\n",
      "2 10\n",
      "2 15\n",
      "2 20\n",
      "2 25\n",
      "2 30\n",
      "2 35\n",
      "2 40\n",
      "2 45\n",
      "2 50\n",
      "2 55\n",
      "2 60\n",
      "2 65\n",
      "2 70\n",
      "2 75\n",
      "2 80\n",
      "2 85\n",
      "2 90\n",
      "2 95\n",
      "2 100\n",
      "2 105\n",
      "2 110\n",
      "2 115\n",
      "2 120\n",
      "2 125\n",
      "2 130\n",
      "2 135\n",
      "2 140\n",
      "2 145\n",
      "2 150\n",
      "2 155\n",
      "2 160\n",
      "2 165\n",
      "2 170\n",
      "2 175\n",
      "2 180\n",
      "2 185\n",
      "2 190\n",
      "2 195\n",
      "2 200\n",
      "3 5\n",
      "3 10\n",
      "3 15\n",
      "3 20\n",
      "3 25\n",
      "3 30\n",
      "3 35\n",
      "3 40\n",
      "3 45\n",
      "3 50\n",
      "3 55\n",
      "3 60\n",
      "3 65\n",
      "3 70\n",
      "3 75\n",
      "3 80\n",
      "3 85\n",
      "3 90\n",
      "3 95\n",
      "3 100\n",
      "3 105\n",
      "3 110\n",
      "3 115\n",
      "3 120\n",
      "3 125\n",
      "3 130\n",
      "3 135\n",
      "3 140\n",
      "3 145\n",
      "3 150\n",
      "3 155\n",
      "3 160\n",
      "3 165\n",
      "3 170\n",
      "3 175\n",
      "3 180\n",
      "3 185\n",
      "3 190\n",
      "3 195\n",
      "3 200\n",
      "4 5\n",
      "4 10\n",
      "4 15\n",
      "4 20\n",
      "4 25\n",
      "4 30\n",
      "4 35\n",
      "4 40\n",
      "4 45\n",
      "4 50\n",
      "4 55\n",
      "4 60\n",
      "4 65\n",
      "4 70\n",
      "4 75\n",
      "4 80\n",
      "4 85\n",
      "4 90\n",
      "4 95\n",
      "4 100\n",
      "4 105\n",
      "4 110\n",
      "4 115\n",
      "4 120\n",
      "4 125\n",
      "4 130\n",
      "4 135\n",
      "4 140\n",
      "4 145\n",
      "4 150\n",
      "4 155\n",
      "4 160\n",
      "4 165\n",
      "4 170\n",
      "4 175\n",
      "4 180\n",
      "4 185\n",
      "4 190\n",
      "4 195\n",
      "4 200\n",
      "5 5\n",
      "5 10\n",
      "5 15\n",
      "5 20\n",
      "5 25\n",
      "5 30\n",
      "5 35\n",
      "5 40\n",
      "5 45\n",
      "5 50\n",
      "5 55\n",
      "5 60\n",
      "5 65\n",
      "5 70\n",
      "5 75\n",
      "5 80\n",
      "5 85\n",
      "5 90\n",
      "5 95\n",
      "5 100\n",
      "5 105\n",
      "5 110\n",
      "5 115\n",
      "5 120\n",
      "5 125\n",
      "5 130\n",
      "5 135\n",
      "5 140\n",
      "5 145\n",
      "5 150\n",
      "5 155\n",
      "5 160\n",
      "5 165\n",
      "5 170\n",
      "5 175\n",
      "5 180\n",
      "5 185\n",
      "5 190\n",
      "5 195\n",
      "5 200\n",
      "6 5\n",
      "6 10\n",
      "6 15\n",
      "6 20\n",
      "6 25\n",
      "6 30\n",
      "6 35\n",
      "6 40\n",
      "6 45\n",
      "6 50\n",
      "6 55\n",
      "6 60\n",
      "6 65\n",
      "6 70\n",
      "6 75\n",
      "6 80\n",
      "6 85\n",
      "6 90\n",
      "6 95\n",
      "6 100\n",
      "6 105\n",
      "6 110\n",
      "6 115\n",
      "6 120\n",
      "6 125\n",
      "6 130\n",
      "6 135\n",
      "6 140\n",
      "6 145\n",
      "6 150\n",
      "6 155\n",
      "6 160\n",
      "6 165\n",
      "6 170\n",
      "6 175\n",
      "6 180\n",
      "6 185\n",
      "6 190\n",
      "6 195\n",
      "6 200\n",
      "7 5\n",
      "7 10\n",
      "7 15\n",
      "7 20\n",
      "7 25\n",
      "7 30\n",
      "7 35\n",
      "7 40\n",
      "7 45\n",
      "7 50\n",
      "7 55\n",
      "7 60\n",
      "7 65\n",
      "7 70\n",
      "7 75\n",
      "7 80\n",
      "7 85\n",
      "7 90\n",
      "7 95\n",
      "7 100\n",
      "7 105\n",
      "7 110\n",
      "7 115\n",
      "7 120\n",
      "7 125\n",
      "7 130\n",
      "7 135\n",
      "7 140\n",
      "7 145\n",
      "7 150\n",
      "7 155\n",
      "7 160\n",
      "7 165\n",
      "7 170\n",
      "7 175\n",
      "7 180\n",
      "7 185\n",
      "7 190\n",
      "7 195\n",
      "7 200\n",
      "8 5\n",
      "8 10\n",
      "8 15\n",
      "8 20\n",
      "8 25\n",
      "8 30\n",
      "8 35\n",
      "8 40\n",
      "8 45\n",
      "8 50\n",
      "8 55\n",
      "8 60\n",
      "8 65\n",
      "8 70\n",
      "8 75\n",
      "8 80\n",
      "8 85\n",
      "8 90\n",
      "8 95\n",
      "8 100\n",
      "8 105\n",
      "8 110\n",
      "8 115\n",
      "8 120\n",
      "8 125\n",
      "8 130\n",
      "8 135\n",
      "8 140\n",
      "8 145\n",
      "8 150\n",
      "8 155\n",
      "8 160\n",
      "8 165\n",
      "8 170\n",
      "8 175\n",
      "8 180\n",
      "8 185\n",
      "8 190\n",
      "8 195\n",
      "8 200\n",
      "9 5\n",
      "9 10\n",
      "9 15\n",
      "9 20\n",
      "9 25\n",
      "9 30\n",
      "9 35\n",
      "9 40\n",
      "9 45\n",
      "9 50\n",
      "9 55\n",
      "9 60\n",
      "9 65\n",
      "9 70\n",
      "9 75\n",
      "9 80\n",
      "9 85\n",
      "9 90\n",
      "9 95\n",
      "9 100\n",
      "9 105\n",
      "9 110\n",
      "9 115\n",
      "9 120\n",
      "9 125\n",
      "9 130\n",
      "9 135\n",
      "9 140\n",
      "9 145\n",
      "9 150\n",
      "9 155\n",
      "9 160\n",
      "9 165\n",
      "9 170\n",
      "9 175\n",
      "9 180\n",
      "9 185\n",
      "9 190\n",
      "9 195\n",
      "9 200\n"
     ]
    }
   ],
   "source": [
    "for num_run in stages.keys():\n",
    "    for epoch in stages[num_run]:\n",
    "        print(num_run,epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5,\n",
       " 10,\n",
       " 15,\n",
       " 20,\n",
       " 25,\n",
       " 30,\n",
       " 35,\n",
       " 40,\n",
       " 45,\n",
       " 50,\n",
       " 55,\n",
       " 60,\n",
       " 65,\n",
       " 70,\n",
       " 75,\n",
       " 80,\n",
       " 85,\n",
       " 90,\n",
       " 95,\n",
       " 100,\n",
       " 105,\n",
       " 110,\n",
       " 115,\n",
       " 120,\n",
       " 125,\n",
       " 130,\n",
       " 135,\n",
       " 140,\n",
       " 145,\n",
       " 150,\n",
       " 155,\n",
       " 160,\n",
       " 165,\n",
       " 170,\n",
       " 175,\n",
       " 180,\n",
       " 185,\n",
       " 190,\n",
       " 195,\n",
       " 200]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "epochs_checked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Configuration from the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train_agent_cifar import Active_Learning_train\n",
    "from inference_agent_cifar import Active_Learning_inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_run =0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_weight_path = os.path.join(config['PROJECT']['group_dir'],'Stage_'+str(num_run-1),'checkpoint','epoch200.ckpt-200')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_weight_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_run = 0\n",
    "for num_run in range(6,10):\n",
    "    if num_run==0:\n",
    "        initial_weight_path = False\n",
    "    else:\n",
    "        initial_weight_path = os.path.join(config['PROJECT']['group_dir'],'Stage_'+str(num_run-1),'checkpoint','epoch200.ckpt-200')\n",
    "        \n",
    "        \n",
    "    NetworkActor =  Active_Learning_train.remote(config, labeled_set, test_set,  num_run, initial_weight_path)\n",
    "    NetworkActor.start_training.remote()\n",
    "    \n",
    "    # Wait util the model is training\n",
    "    while True:\n",
    "        time.sleep(10)\n",
    "        try:\n",
    "            progress_id = NetworkActor.isTraining.remote()\n",
    "            response = ray.get(progress_id)\n",
    "            break\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    # wait until the model finish training\n",
    "    while True:\n",
    "        time.sleep(10)\n",
    "        progress_id = NetworkActor.isTraining.remote()\n",
    "        response = ray.get(progress_id)\n",
    "        if not response:\n",
    "            break\n",
    "    \n",
    "    NetworkActor.__ray_terminate__.remote()\n",
    "    \n",
    "    del NetworkActor\n",
    "    \n",
    "    if config[\"TRAIN\"][\"w_l_loss\"] > 0:\n",
    "        \n",
    "        weight_file = os.path.join(config['PROJECT']['group_dir'],'Stage_'+str(num_run),'checkpoint','epoch200.ckpt-200')\n",
    "        \n",
    "        AL_inference = Active_Learning_inference.remote( config, unlabeled_set, num_run, weight_file)\n",
    "        AL_inference.evaluate.remote()\n",
    "\n",
    "        run_dir   = os.path.join(config[\"PROJECT\"][\"group_dir\"],\"Stage_\"+str(num_run))\n",
    "        ordered_indexes   = os.path.join(run_dir, \"ordered_indexes.csv\")\n",
    "\n",
    "        # wait the file qith the scores is generated\n",
    "        while True:\n",
    "            time.sleep(10)\n",
    "            if os.path.isfile(ordered_indexes):\n",
    "                break\n",
    "\n",
    "        # read the scores file and create the new labeled set and unlabeled set to repeat the trainig\n",
    "        pd_ordered_indexes = pd.read_csv(ordered_indexes)\n",
    "        new_annotated_data = list(pd_ordered_indexes.iloc[:config[\"RUNS\"][\"ADDENDUM\"]]['indexes'].to_numpy())\n",
    "        labeled_set += new_annotated_data\n",
    "        unlabeled_set =  list(pd_ordered_indexes.iloc[config[\"RUNS\"][\"ADDENDUM\"]:]['indexes'].to_numpy())\n",
    "    else :\n",
    "        num_images = (num_run+2)*config[\"RUNS\"][\"ADDENDUM\"]\n",
    "        labeled_set = indices[: num_images]\n",
    "        unlabeled_set = indices[num_images :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
