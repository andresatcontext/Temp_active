{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/reminiz/ReminizML2/python_env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/reminiz/ReminizML2/python_env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/reminiz/ReminizML2/python_env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/reminiz/ReminizML2/python_env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/reminiz/ReminizML2/python_env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/reminiz/ReminizML2/python_env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "2021-01-12 17:50:06,802\tINFO worker.py:634 -- Connecting to existing Ray cluster at address: 192.168.8.51:6379\n"
     ]
    }
   ],
   "source": [
    "from AutoML import AutoML, DataNet, AutoMLDataset\n",
    "#DataNet().restart_datanodes()\n",
    "classes_semantics = [113988, 113989, 113990]\n",
    "dataset = AutoMLDataset(name=\"person_classification\")#, semantics=classes_semantics, crops=True) #, override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-12 17:50:07,085\tINFO worker.py:634 -- Connecting to existing Ray cluster at address: 192.168.8.51:6379\n",
      "2021-01-12 17:50:07,086\tERROR worker.py:643 -- Calling ray.init() again after it has already been called.\n"
     ]
    }
   ],
   "source": [
    "import ray\n",
    "ray.init(address=\"auto\", ignore_reinit_error=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_images_stage = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the indexes to emulate the labeled set\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "list_classes = list(dataset.dataset_header['train_images'].keys())\n",
    "nb_classes = len(list_classes)        \n",
    "classes={}\n",
    "files = []\n",
    "labels = []\n",
    "nb_img_per_class = np.zeros(nb_classes, dtype = np.int32)\n",
    "classes_cardinality = {}\n",
    "\n",
    "for class_name in list_classes:\n",
    "    class_index = list_classes.index(class_name)\n",
    "    classes_cardinality[class_name] = len(dataset.dataset_header['train_images'][class_name])\n",
    "    nb_img_per_class[class_index] = classes_cardinality[class_name]\n",
    "    start = len(files)\n",
    "    id_files = dataset.dataset_header[\"train_images\"][class_name]\n",
    "    files+=id_files\n",
    "    labels+=[class_index] * len(id_files)\n",
    "    end = len(files)\n",
    "    classes[class_index]=range(start, end)\n",
    "\n",
    "    \n",
    "all_files = np.array(files)\n",
    "all_labels = np.array(labels)\n",
    "indices = list(range(len(files)))\n",
    "random.seed(101)\n",
    "random.shuffle(indices)\n",
    "labeled_set_index = indices[:add_images_stage ]\n",
    "unlabeled_set_index = indices[add_images_stage :]\n",
    "\n",
    "files_labeled_set = list(all_files[labeled_set_index])\n",
    "files_unlabeled_set = list(all_files[unlabeled_set_index])\n",
    "\n",
    "labels_labeled_set = list(all_labels[labeled_set_index])\n",
    "labels_unlabeled_set = list(all_labels[unlabeled_set_index])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'DATASET': {'Data_augementation': True, 'original_size': 256, 'pad': False, 'random_crop': True, 'random_crop_pad': 30, 'random_flip': True, 'random_greyscale': False, 'random_hue': False, 'rot90': False, 'random_brightness': False, 'random_saturation': False}, 'NETWORK': {'Backbone': 'ResNet50', 'INPUT_SIZE': 256, 'MARGIN': 1.0, 'embedding_size': 128}, 'PROJECT': {'dataset_name': 'person_classification', 'group': 'Active_Learning_2', 'group_dir': '/mnt/Ressources/Andres/runs/Active_Learning_2', 'project': 'Active_Learning_Datanet', 'project_dir': '/mnt/Ressources/Andres/runs'}, 'TEST': {'batch_size': 16}, 'TRAIN': {'EPOCH_SLIT': 80, 'EPOCH_WARMUP': 2, 'EPOCH_WHOLE': 120, 'MILESTONES': [140, 180], 'batch_size': 32, 'lr': 0.0025, 'test_each': 5, 'transfer_weight_path': '/mnt/Ressources/Andres/runs/imagenet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5', 'weight_lossnet_loss': 1.0, 'weight_decay': 2e-05, 'apply_weight_decay': False}}\n"
     ]
    }
   ],
   "source": [
    "# load defaulft config\n",
    "import yaml\n",
    "\n",
    "config_path = '/mnt/Ressources/Andres/Temp_active/configs/Datanet_AL_2.yml'\n",
    "\n",
    "with open(config_path) as file:\n",
    "    # The FullLoader parameter handles the conversion from YAML\n",
    "    # scalar values to Python the dictionary format\n",
    "    config = yaml.load(file, Loader=yaml.FullLoader)\n",
    "\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train_agent_classification_AL import Active_Learning_train\n",
    "from inference_agent_classification import Active_Learning_inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "resumeat = 0"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "resumeat = 0\n",
    "\n",
    "for num_run in range(resumeat):\n",
    "    run_dir   = os.path.join(config[\"PROJECT\"][\"group_dir\"],\"Stage_\"+str(num_run))\n",
    "    ordered_indexes   = os.path.join(run_dir, \"ordered_indexes.csv\")\n",
    "\n",
    "    # read the scores file and create the new labeled set and unlabeled set to repeat the trainig\n",
    "    pd_ordered_indexes = pd.read_csv(ordered_indexes)\n",
    "    \n",
    "    new_files_set = pd_ordered_indexes['files'].values\n",
    "    new_files_set = [i[2:-1] for i in new_files_set]\n",
    "    new_labels_set = pd_ordered_indexes['labels'].values\n",
    "    \n",
    "    files_labeled_set    += list(new_files_set[:5000])\n",
    "    labels_labeled_set   += list(new_labels_set[:5000])\n",
    "\n",
    "    files_unlabeled_set  = list(new_files_set[5000:])\n",
    "    labels_unlabeled_set = list(new_labels_set[5000:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "resume_model_path = os.path.join(config['PROJECT']['group_dir'],'Stage_'+str(1),'checkpoints','checkpoint.200.hdf5')\n",
    "AL_inference = Active_Learning_inference.remote(config , files_unlabeled_set, labels_unlabeled_set,classes_semantics , 1, resume_model_path)\n",
    "AL_inference.inference.remote()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=10956)\u001b[0m /home/reminiz/ReminizML2/python_env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\u001b[2m\u001b[36m(pid=10956)\u001b[0m   _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "\u001b[2m\u001b[36m(pid=10956)\u001b[0m /home/reminiz/ReminizML2/python_env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\u001b[2m\u001b[36m(pid=10956)\u001b[0m   _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "\u001b[2m\u001b[36m(pid=10956)\u001b[0m /home/reminiz/ReminizML2/python_env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\u001b[2m\u001b[36m(pid=10956)\u001b[0m   _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "\u001b[2m\u001b[36m(pid=10956)\u001b[0m /home/reminiz/ReminizML2/python_env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\u001b[2m\u001b[36m(pid=10956)\u001b[0m   _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "\u001b[2m\u001b[36m(pid=10956)\u001b[0m /home/reminiz/ReminizML2/python_env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\u001b[2m\u001b[36m(pid=10956)\u001b[0m   _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "\u001b[2m\u001b[36m(pid=10956)\u001b[0m /home/reminiz/ReminizML2/python_env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\u001b[2m\u001b[36m(pid=10956)\u001b[0m   np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "\u001b[2m\u001b[36m(pid=10956)\u001b[0m 2021-01-12 17:50:10.230163: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "\u001b[2m\u001b[36m(pid=10956)\u001b[0m 2021-01-12 17:50:10.255022: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3300285000 Hz\n",
      "\u001b[2m\u001b[36m(pid=10956)\u001b[0m 2021-01-12 17:50:10.255826: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x5caf4c0 executing computations on platform Host. Devices:\n",
      "\u001b[2m\u001b[36m(pid=10956)\u001b[0m 2021-01-12 17:50:10.255849: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>\n",
      "\u001b[2m\u001b[36m(pid=10956)\u001b[0m 2021-01-12 17:50:10.421859: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x5d3c750 executing computations on platform CUDA. Devices:\n",
      "\u001b[2m\u001b[36m(pid=10956)\u001b[0m 2021-01-12 17:50:10.421909: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): TITAN RTX, Compute Capability 7.5\n",
      "\u001b[2m\u001b[36m(pid=10956)\u001b[0m 2021-01-12 17:50:10.422175: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: \n",
      "\u001b[2m\u001b[36m(pid=10956)\u001b[0m name: TITAN RTX major: 7 minor: 5 memoryClockRate(GHz): 1.77\n",
      "\u001b[2m\u001b[36m(pid=10956)\u001b[0m pciBusID: 0000:03:00.0\n",
      "\u001b[2m\u001b[36m(pid=10956)\u001b[0m totalMemory: 23.65GiB freeMemory: 23.49GiB\n",
      "\u001b[2m\u001b[36m(pid=10956)\u001b[0m 2021-01-12 17:50:10.422215: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0\n",
      "\u001b[2m\u001b[36m(pid=10956)\u001b[0m 2021-01-12 17:50:10.426187: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "\u001b[2m\u001b[36m(pid=10956)\u001b[0m 2021-01-12 17:50:10.426219: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 \n",
      "\u001b[2m\u001b[36m(pid=10956)\u001b[0m 2021-01-12 17:50:10.426240: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N \n",
      "\u001b[2m\u001b[36m(pid=10956)\u001b[0m 2021-01-12 17:50:10.426365: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 22852 MB memory) -> physical GPU (device: 0, name: TITAN RTX, pci bus id: 0000:03:00.0, compute capability: 7.5)\n",
      "\u001b[2m\u001b[36m(pid=10956)\u001b[0m /home/reminiz/ReminizML2/python_env/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\u001b[2m\u001b[36m(pid=10956)\u001b[0m   _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "\u001b[2m\u001b[36m(pid=10956)\u001b[0m /home/reminiz/ReminizML2/python_env/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\u001b[2m\u001b[36m(pid=10956)\u001b[0m   _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "\u001b[2m\u001b[36m(pid=10956)\u001b[0m /home/reminiz/ReminizML2/python_env/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\u001b[2m\u001b[36m(pid=10956)\u001b[0m   _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "\u001b[2m\u001b[36m(pid=10956)\u001b[0m /home/reminiz/ReminizML2/python_env/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\u001b[2m\u001b[36m(pid=10956)\u001b[0m   _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "\u001b[2m\u001b[36m(pid=10956)\u001b[0m /home/reminiz/ReminizML2/python_env/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\u001b[2m\u001b[36m(pid=10956)\u001b[0m   _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "\u001b[2m\u001b[36m(pid=10956)\u001b[0m /home/reminiz/ReminizML2/python_env/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\u001b[2m\u001b[36m(pid=10956)\u001b[0m   np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "\u001b[2m\u001b[36m(pid=10956)\u001b[0m wandb: Tracking run with wandb version 0.8.36\n",
      "\u001b[2m\u001b[36m(pid=10956)\u001b[0m wandb: Wandb version 0.10.13 is available!  To upgrade, please run:\n",
      "\u001b[2m\u001b[36m(pid=10956)\u001b[0m wandb:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(pid=10956)\u001b[0m wandb: Run data is saved locally in ../../../Trainings/wandb/wandb/run-20210112_165010-3pvb1i63\n",
      "\u001b[2m\u001b[36m(pid=10956)\u001b[0m wandb: Syncing run Train_0\n",
      "\u001b[2m\u001b[36m(pid=10956)\u001b[0m wandb: ‚≠êÔ∏è View project at http://192.168.8.51:8080/reminiz/Active_Learning_Datanet\n",
      "\u001b[2m\u001b[36m(pid=10956)\u001b[0m wandb: üöÄ View run at http://192.168.8.51:8080/reminiz/Active_Learning_Datanet/runs/3pvb1i63\n",
      "\u001b[2m\u001b[36m(pid=10956)\u001b[0m wandb: Run `wandb off` to turn off syncing.\n",
      "\u001b[2m\u001b[36m(pid=10956)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=10956)\u001b[0m Subset set to : train\n",
      "\u001b[2m\u001b[36m(pid=10956)\u001b[0m ['Partially Dressed', 'Dressed', 'Explicit Dressed']\n",
      "\u001b[2m\u001b[36m(pid=10956)\u001b[0m \u001b[1;36mTrain_Stage_0\u001b[0;0m The backbone is:  ResNet50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=10956)\u001b[0m WARNING:tensorflow:From /mnt/Ressources/Andres/Temp_active/data_pipeline/Classification_dataset_AL.py:131: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=10956)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=10956)\u001b[0m tf.py_func is deprecated in TF V2. Instead, use\n",
      "\u001b[2m\u001b[36m(pid=10956)\u001b[0m     tf.py_function, which takes a python function which manipulates tf eager\n",
      "\u001b[2m\u001b[36m(pid=10956)\u001b[0m     tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "\u001b[2m\u001b[36m(pid=10956)\u001b[0m     an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "\u001b[2m\u001b[36m(pid=10956)\u001b[0m     means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "\u001b[2m\u001b[36m(pid=10956)\u001b[0m     being differentiable using a gradient tape.\n",
      "\u001b[2m\u001b[36m(pid=10956)\u001b[0m     \n",
      "\u001b[2m\u001b[36m(pid=10956)\u001b[0m WARNING:tensorflow:From /home/reminiz/ReminizML2/python_env/lib/python3.7/site-packages/tensorflow/python/ops/control_flow_ops.py:3632: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=10956)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=10956)\u001b[0m Colocations handled automatically by placer.\n",
      "\u001b[2m\u001b[36m(pid=10956)\u001b[0m WARNING:tensorflow:From /home/reminiz/ReminizML2/python_env/lib/python3.7/site-packages/tensorflow/python/ops/image_ops_impl.py:1241: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=10956)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=10956)\u001b[0m Deprecated in favor of operator or tf.math.divide.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=10956)\u001b[0m \u001b[1;36mTrain_Stage_0\u001b[0;0m (transfer learning) Loading weigths by name from:  /mnt/Ressources/Andres/runs/imagenet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=10956)\u001b[0m 2021-01-12 17:50:19,993\tINFO worker.py:634 -- Connecting to existing Ray cluster at address: 192.168.8.51:6379\n",
      "\u001b[2m\u001b[36m(pid=10956)\u001b[0m 2021-01-12 17:50:19,993\tERROR worker.py:643 -- Calling ray.init() again after it has already been called.\n",
      "\u001b[2m\u001b[36m(pid=10956)\u001b[0m WARNING:tensorflow:Output \"Embedding\" missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to \"Embedding\".\n",
      "\u001b[2m\u001b[36m(pid=10956)\u001b[0m WARNING:tensorflow:Output \"Embedding\" missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to \"Embedding\".\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=10956)\u001b[0m \u001b[1;36mTrain_Stage_0\u001b[0;0m Init done\n",
      "\u001b[2m\u001b[36m(pid=10956)\u001b[0m \u001b[1;36mTrain_Stage_0\u001b[0;0m Start training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=10956)\u001b[0m WARNING:tensorflow:From /home/reminiz/ReminizML2/python_env/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=10956)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=10956)\u001b[0m Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Current Epoch': 1, 'Total Epoch': 200, 'Current Step': 1, 'Total Steps': 31400, 'Progress': 0.0, 'steps_per_epoch': 157, 'status': 'Idle'}\n",
      "{'Current Epoch': 1, 'Total Epoch': 200, 'Current Step': 1, 'Total Steps': 31400, 'Progress': 0.0, 'steps_per_epoch': 157, 'status': 'Training'}\n",
      "\u001b[2m\u001b[36m(pid=10956)\u001b[0m Epoch 1/200\n",
      "{'Current Epoch': 1, 'Total Epoch': 200, 'Current Step': 1, 'Total Steps': 31400, 'Progress': 0.0, 'steps_per_epoch': 157, 'status': 'Training'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=10956)\u001b[0m 2021-01-12 17:50:51.196002: I tensorflow/stream_executor/dso_loader.cc:152] successfully opened CUDA library libcublas.so.10.0 locally\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Current Epoch': 1, 'Total Epoch': 200, 'Current Step': 33, 'Total Steps': 31400, 'Progress': 0.11, 'steps_per_epoch': 157, 'status': 'Training'}\n",
      "{'Current Epoch': 1, 'Total Epoch': 200, 'Current Step': 80, 'Total Steps': 31400, 'Progress': 0.25, 'steps_per_epoch': 157, 'status': 'Training'}\n",
      "{'Current Epoch': 1, 'Total Epoch': 200, 'Current Step': 127, 'Total Steps': 31400, 'Progress': 0.4, 'steps_per_epoch': 157, 'status': 'Training'}\n",
      "\u001b[2m\u001b[36m(pid=10956)\u001b[0m  - 46s - loss: 1.2346 - c_pred_loss: 0.8469 - l_pred_w_loss: 0.3877 - l_pred_s_loss: 0.3877 - c_pred_sparse_categorical_accuracy: 0.7542\n",
      "\u001b[2m\u001b[36m(pid=10956)\u001b[0m Epoch 2/200\n",
      "{'Current Epoch': 0, 'Total Epoch': 200, 'Current Step': 162, 'Total Steps': 31400, 'Progress': 0.52, 'steps_per_epoch': 157, 'status': 'Training'}\n",
      "{'Current Epoch': 0, 'Total Epoch': 200, 'Current Step': 209, 'Total Steps': 31400, 'Progress': 0.66, 'steps_per_epoch': 157, 'status': 'Training'}\n",
      "{'Current Epoch': 0, 'Total Epoch': 200, 'Current Step': 256, 'Total Steps': 31400, 'Progress': 0.81, 'steps_per_epoch': 157, 'status': 'Training'}\n",
      "{'Current Epoch': 0, 'Total Epoch': 200, 'Current Step': 303, 'Total Steps': 31400, 'Progress': 0.96, 'steps_per_epoch': 157, 'status': 'Training'}\n",
      "\u001b[2m\u001b[36m(pid=10956)\u001b[0m  - 34s - loss: 1.0513 - c_pred_loss: 0.7303 - l_pred_w_loss: 0.3210 - l_pred_s_loss: 0.3210 - c_pred_sparse_categorical_accuracy: 0.7605\n",
      "\u001b[2m\u001b[36m(pid=10956)\u001b[0m Epoch 3/200\n",
      "{'Current Epoch': 1, 'Total Epoch': 200, 'Current Step': 349, 'Total Steps': 31400, 'Progress': 1.11, 'steps_per_epoch': 157, 'status': 'Training'}\n",
      "{'Current Epoch': 1, 'Total Epoch': 200, 'Current Step': 396, 'Total Steps': 31400, 'Progress': 1.26, 'steps_per_epoch': 157, 'status': 'Training'}\n",
      "{'Current Epoch': 1, 'Total Epoch': 200, 'Current Step': 443, 'Total Steps': 31400, 'Progress': 1.4, 'steps_per_epoch': 157, 'status': 'Training'}\n",
      "\u001b[2m\u001b[36m(pid=10956)\u001b[0m  - 34s - loss: 1.0385 - c_pred_loss: 0.7272 - l_pred_w_loss: 0.3113 - l_pred_s_loss: 0.3113 - c_pred_sparse_categorical_accuracy: 0.7607\n",
      "\u001b[2m\u001b[36m(pid=10956)\u001b[0m Epoch 4/200\n",
      "{'Current Epoch': 2, 'Total Epoch': 200, 'Current Step': 490, 'Total Steps': 31400, 'Progress': 1.56, 'steps_per_epoch': 157, 'status': 'Training'}\n",
      "{'Current Epoch': 2, 'Total Epoch': 200, 'Current Step': 537, 'Total Steps': 31400, 'Progress': 1.71, 'steps_per_epoch': 157, 'status': 'Training'}\n",
      "{'Current Epoch': 2, 'Total Epoch': 200, 'Current Step': 583, 'Total Steps': 31400, 'Progress': 1.85, 'steps_per_epoch': 157, 'status': 'Training'}\n",
      "\u001b[2m\u001b[36m(pid=10956)\u001b[0m  - 34s - loss: 0.9959 - c_pred_loss: 0.6982 - l_pred_w_loss: 0.2977 - l_pred_s_loss: 0.2977 - c_pred_sparse_categorical_accuracy: 0.7609\n",
      "\u001b[2m\u001b[36m(pid=10956)\u001b[0m Epoch 5/200\n",
      "{'Current Epoch': 3, 'Total Epoch': 200, 'Current Step': 630, 'Total Steps': 31400, 'Progress': 2.01, 'steps_per_epoch': 157, 'status': 'Training'}\n",
      "{'Current Epoch': 3, 'Total Epoch': 200, 'Current Step': 677, 'Total Steps': 31400, 'Progress': 2.15, 'steps_per_epoch': 157, 'status': 'Training'}\n",
      "{'Current Epoch': 3, 'Total Epoch': 200, 'Current Step': 724, 'Total Steps': 31400, 'Progress': 2.3, 'steps_per_epoch': 157, 'status': 'Training'}\n",
      "{'Current Epoch': 3, 'Total Epoch': 200, 'Current Step': 771, 'Total Steps': 31400, 'Progress': 2.46, 'steps_per_epoch': 157, 'status': 'Training'}\n",
      "{'Current Epoch': 3, 'Total Epoch': 200, 'Current Step': 786, 'Total Steps': 31400, 'Progress': 2.5, 'steps_per_epoch': 157, 'status': 'Training'}\n",
      "{'Current Epoch': 3, 'Total Epoch': 200, 'Current Step': 786, 'Total Steps': 31400, 'Progress': 2.5, 'steps_per_epoch': 157, 'status': 'Training'}\n"
     ]
    }
   ],
   "source": [
    "for num_run in range(resumeat,10):\n",
    "\n",
    "    prev_num_run = num_run-1\n",
    "    if num_run==0:\n",
    "        resume_model_path = False\n",
    "    else:\n",
    "        resume_model_path = os.path.join(config['PROJECT']['group_dir'],'Stage_'+str(prev_num_run),'checkpoints','checkpoint.200.hdf5')\n",
    "        \n",
    "    Active_Learning = Active_Learning_train.remote(config, \n",
    "                                            files_labeled_set,\n",
    "                                            labels_labeled_set,\n",
    "                                            classes_semantics,\n",
    "                                            num_run=num_run,\n",
    "                                            resume_model_path=resume_model_path,\n",
    "                                            resume = False)\n",
    "    \n",
    "    Active_Learning.start_training.remote()\n",
    "    \n",
    "    # Wait util the model is training\n",
    "    while True:\n",
    "        time.sleep(10)\n",
    "        try:\n",
    "            progress_id = Active_Learning.isTraining.remote()\n",
    "            response = ray.get(progress_id)\n",
    "            break\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    # wait until the model finish training\n",
    "    while True:\n",
    "        time.sleep(10)\n",
    "        progress_id = Active_Learning.isTraining.remote()\n",
    "        response = ray.get(progress_id)\n",
    "        \n",
    "        get_progress = Active_Learning.get_progress.remote()\n",
    "        print(ray.get(get_progress))\n",
    "        \n",
    "        if not response:\n",
    "            break\n",
    "    \n",
    "    del Active_Learning\n",
    "\n",
    "    resume_model_path = os.path.join(config['PROJECT']['group_dir'],'Stage_'+str(num_run),'checkpoints','checkpoint.200.hdf5')\n",
    "    AL_inference = Active_Learning_inference.remote(config , files_unlabeled_set, labels_unlabeled_set, classes_semantics, num_run, resume_model_path)\n",
    "    AL_inference.inference.remote()\n",
    "\n",
    "    run_dir   = os.path.join(config[\"PROJECT\"][\"group_dir\"],\"Stage_\"+str(num_run))\n",
    "    ordered_indexes   = os.path.join(run_dir, \"ordered_indexes.csv\")\n",
    "\n",
    "    # wait the file qith the scores is generated\n",
    "    while True:\n",
    "        time.sleep(10)\n",
    "        if os.path.isfile(ordered_indexes):\n",
    "            break\n",
    "    try:\n",
    "        AL_inference.__ray_terminate__.remote()\n",
    "    except:\n",
    "        print(\"Here\")\n",
    "        \n",
    "    del AL_inference\n",
    "\n",
    "    # read the scores file and create the new labeled set and unlabeled set to repeat the trainig\n",
    "    pd_ordered_indexes = pd.read_csv(ordered_indexes)\n",
    "    \n",
    "    new_files_set = pd_ordered_indexes['files'].values\n",
    "    new_files_set = [i[2:-1] for i in new_files_set]\n",
    "    new_labels_set = pd_ordered_indexes['labels'].values\n",
    "    \n",
    "    files_labeled_set    += list(new_files_set[:add_images_stage])\n",
    "    labels_labeled_set   += list(new_labels_set[:add_images_stage])\n",
    "\n",
    "    files_unlabeled_set  = list(new_files_set[add_images_stage:])\n",
    "    labels_unlabeled_set = list(new_labels_set[add_images_stage:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
