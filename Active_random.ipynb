{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Init ray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load default config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "ray.init(address=\"auto\", ignore_reinit_error=True)\n",
    "# load defaulft config\n",
    "import yaml\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "config_path = './configs/Active_v0.yml'\n",
    "\n",
    "with open(config_path) as file:\n",
    "    # The FullLoader parameter handles the conversion from YAML\n",
    "    # scalar values to Python the dictionary format\n",
    "    config = yaml.load(file, Loader=yaml.FullLoader)\n",
    "\n",
    "# create base dir and gr\n",
    "if os.path.exists(config[\"PROJECT\"][\"project_dir\"]) is False:\n",
    "    os.mkdir(config[\"PROJECT\"][\"project_dir\"])\n",
    "\n",
    "if os.path.exists(config[\"PROJECT\"][\"group_dir\"]) is False:\n",
    "    os.mkdir(config[\"PROJECT\"][\"group_dir\"])\n",
    "    \n",
    "    \n",
    "# Get the data to annotate\n",
    "\n",
    "#############################################################################################\n",
    "# LOAD DATA\n",
    "#############################################################################################\n",
    "from data_utils import CIFAR10Data\n",
    "# Load data\n",
    "cifar10_data = CIFAR10Data()\n",
    "num_classes = len(cifar10_data.classes)\n",
    "x_train, y_train, x_test, y_test = cifar10_data.get_data(subtract_mean=True)\n",
    "\n",
    "indices = list(range(len(x_train)))\n",
    "random.seed(101)\n",
    "random.shuffle(indices)\n",
    "labeled_set = indices[:config[\"RUNS\"][\"ADDENDUM\"] ]\n",
    "unlabeled_set = indices[config[\"RUNS\"][\"ADDENDUM\"] :]\n",
    "\n",
    "config[\"NETWORK\"][\"INPUT_SIZE\"] =  x_train[0].shape[0]\n",
    "config[\"NETWORK\"][\"CLASSES\"] = cifar10_data.classes\n",
    "\n",
    "# test with all the images\n",
    "NUM_IMAGES_TEST = len(x_test)\n",
    "# Initialize a labeled dataset by randomly sampling K=ADDENDUM=1,000 data points from the entire dataset.\n",
    "test_set = list(range(NUM_IMAGES_TEST))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train_agent_cifar_keras import Active_Learning_train\n",
    "\n",
    "\n",
    "num_run =0\n",
    "initial_weight_path = os.path.join(config['PROJECT']['group_dir'],'Stage_'+str(num_run-1),'checkpoint','epoch200.ckpt-200')\n",
    "initial_weight_path = False\n",
    "\n",
    "for num_run in range(10):\n",
    "    prev_num_run = num_run-1\n",
    "    if num_run==0:\n",
    "        resume_model_path = False\n",
    "    else:\n",
    "        resume_model_path = os.path.join(config['PROJECT']['group_dir'],'Stage_'+str(num_run-1),'checkpoints','checkpoint.200.hdf5')\n",
    "        \n",
    "        \n",
    "    NetworkActor =  Active_Learning_train.remote(config, labeled_set, test_set,  num_run, resume_model_path, resume=False)\n",
    "    NetworkActor.start_training.remote()\n",
    "    \n",
    "    # Wait util the model is training\n",
    "    while True:\n",
    "        time.sleep(10)\n",
    "        try:\n",
    "            progress_id = NetworkActor.isTraining.remote()\n",
    "            response = ray.get(progress_id)\n",
    "            break\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    # wait until the model finish training\n",
    "    while True:\n",
    "        time.sleep(10)\n",
    "        progress_id = NetworkActor.isTraining.remote()\n",
    "        response = ray.get(progress_id)\n",
    "        if not response:\n",
    "            break\n",
    "    \n",
    "    NetworkActor.__ray_terminate__.remote()\n",
    "    \n",
    "    del NetworkActor\n",
    "\n",
    "    num_images = (num_run+2)*config[\"RUNS\"][\"ADDENDUM\"]\n",
    "    labeled_set = indices[: num_images]\n",
    "    unlabeled_set = indices[num_images :]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "    if config[\"TRAIN\"][\"w_l_loss\"] > 0:\n",
    "        \n",
    "        weight_file = os.path.join(config['PROJECT']['group_dir'],'Stage_'+str(num_run),'checkpoint','epoch200.ckpt-200')\n",
    "        \n",
    "        AL_inference = Active_Learning_inference.remote( config, unlabeled_set, num_run, weight_file)\n",
    "        AL_inference.evaluate.remote()\n",
    "\n",
    "        run_dir   = os.path.join(config[\"PROJECT\"][\"group_dir\"],\"Stage_\"+str(num_run))\n",
    "        ordered_indexes   = os.path.join(run_dir, \"ordered_indexes.csv\")\n",
    "\n",
    "        # wait the file qith the scores is generated\n",
    "        while True:\n",
    "            time.sleep(10)\n",
    "            if os.path.isfile(ordered_indexes):\n",
    "                break\n",
    "\n",
    "        # read the scores file and create the new labeled set and unlabeled set to repeat the trainig\n",
    "        pd_ordered_indexes = pd.read_csv(ordered_indexes)\n",
    "        new_annotated_data = list(pd_ordered_indexes.iloc[:config[\"RUNS\"][\"ADDENDUM\"]]['indexes'].to_numpy())\n",
    "        labeled_set += new_annotated_data\n",
    "        unlabeled_set =  list(pd_ordered_indexes.iloc[config[\"RUNS\"][\"ADDENDUM\"]:]['indexes'].to_numpy())\n",
    "    else :"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
